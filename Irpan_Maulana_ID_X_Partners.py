# -*- coding: utf-8 -*-
"""Clean_Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O6uX8Jhf4P69Oj2HQk1vMOFIEpJvxcTt

# IMPORT LIBRARY
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split,GridSearchCV, StratifiedKFold
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay, mutual_info_score
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

"""# LOAD DATA"""

df_original = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/loan_data_2007_2014.csv')

df_loan = df_original.copy()

df_loan.head(5)

"""# EDA"""

df_loan.info()

df_loan.describe().T

df_cleaned = df_loan.dropna(subset=['loan_status'])

nilai_unik = df_cleaned['loan_status'].nunique()
print(f"Total jumlah kategori unik: {nilai_unik}")
jumlah_nilaiUnik = df_cleaned['loan_status'].value_counts()
persentase_nilaiUnik = df_cleaned['loan_status'].value_counts(normalize=True) * 100
summary_df = pd.DataFrame({'Jumlah': jumlah_nilaiUnik,
    'Persentase (%)': persentase_nilaiUnik.round(2)})
print(summary_df.head(20))

"""# MEMBUAT KOLOM TARGET(credit_risk)

*   Membuat DataFrame baru yang berisi status current, In Grace Period, Late (16-30 days) lalu menghapus kolomnya, mejadi DataSet tanpal label
*   status current, In Grace Period, Late (16-30 days) tidak bisa di kategorikan sebagai pinjaman "Good" atau "Bad" karena pinjaman masih berjalan dan belum selesai
"""

status_Current = ['Current', 'In Grace Period', 'Late (16-30 days)']
df_2 = df_loan[df_loan['loan_status'].isin(status_Current)].copy()
df_without_label = df_2.drop(columns=['loan_status'])
print(f"Data dengan status 'belum selesai' telah dipisahkan. Jumlah baris: {len(df_without_label)}")

"""

*   Membuat kolom credit_risk berdasarkan kolom loan_status. credit_risk akan digunakan sebagai kolom target
*   Status "Fully Paid", "Does not meet the credit policy. Status:Fully Paid" dikategorikan sebagai peminjam "Good"
*   Status "Charged Off", "Default", "Does not meet the credit policy. Status:Charged Off", "Late (31-120 days)" dikategorikan sebagai peminjam "Bad"



"""

#Fungsi Untuk mengubah setiap nilai unik pada loan_status menjadi 0 , 1
def good_bad(status):
    if status in ['Fully Paid', 'Does not meet the credit policy. Status:Fully Paid']:
        return 0  #Good
    elif status in ['Charged Off', 'Default', 'Does not meet the credit policy. Status:Charged Off', 'Late (31-120 days)']:
        return 1  # Bad


df_loan['credit_risk'] = df_loan['loan_status'].apply(good_bad)

df_loan.dropna(subset=['credit_risk'], inplace=True)

df_loan.drop(columns=['loan_status'], inplace=True)

df_loan['credit_risk'] = df_loan['credit_risk'].astype(int)

credit_cols = df_loan["credit_risk"].value_counts()
target = df_loan['credit_risk'].value_counts()
label = target.index

plt.figure(figsize=(5, 5))

# Define custom colors for Good and Bad
colors = ['lightblue', 'red']

plt.pie(target, labels=label, autopct='%.2f%%', colors=colors)
print(credit_cols)
plt.title('Target Variable')
plt.show()

"""Jumlah Good dan Bad sangat jauh dan tetap dipertahankan:

*   persentase Bad masih di atas 20% dan itu masih cukup

# CHECK MISSING VALUE
"""

df_loan.isnull().sum()

null_value = df_loan.isnull().sum()
jumlah_data = len(df_loan)
persentase_null = (null_value / jumlah_data) * 100

null_info = pd.DataFrame({
    'Jumlah Hilang': null_value,
    'Persentase Hilang': persentase_null
})

null_info2 = null_info[null_info['Jumlah Hilang'] > 0].sort_values(by='Persentase Hilang', ascending=False)

jumlah_kolom_hilang = len(null_info2)
print(f"Jumlah kolom yang nilai null:{jumlah_kolom_hilang}")
print("-" * 50)
print(null_info2)

#CHECK JUMLAH DATA "df_loan" DAN "df_without_label"
df1 = df_loan.shape,
df2 = df_without_label.shape

df_info = {
    'df_loan': df1,
    'df_without_label': df2}
print(df_info)

df_loan.info()

"""# CHECK DUPLICATE"""

df_loan.duplicated().sum()

# Cara sederhana menggunakan select_dtypes untuk langsung memilih kolom berdasarkan tipenya
kolom_numerik = df_loan.select_dtypes(include=np.number).columns.tolist()
kolom_kategorikal = df_loan.select_dtypes(include=['category', 'object', 'bool']).columns.tolist()

print(f"Kolom Numerik ({len(kolom_numerik)} kolom):")
print(kolom_numerik)
print(f"Kolom Kategorikal ({len(kolom_kategorikal)} kolom):")
print(kolom_kategorikal)

"""# UNIVARIATE ANALYSIS

## KOLOM KATEGORIKAL
"""

for column in kolom_kategorikal:
    print(df_loan[column].value_counts().nlargest(20))
    jumlah_kategori_unik = df_loan[column].nunique()
    plt.figure(figsize=(10, 6), layout='constrained')
    top_20 = df_loan[column].value_counts().nlargest(20).index
    sns.countplot(y=column, data=df_loan[df_loan[column].isin(top_20)], order=top_20, palette='viridis')
    plt.title(f'{column} (Total Unik: {jumlah_kategori_unik})', fontsize=15)
    plt.xlabel('Frekuensi', fontsize=12)
    plt.ylabel(f'Nilai Unik - {column}', fontsize=12)

    plt.show()

"""## KOLOM NUMERIK"""

sns.set_style('whitegrid')

print("Membuat histogram untuk setiap kolom numerik...")

# Loop melalui setiap nama kolom dalam list 'kolom_numerik'
for column in kolom_numerik:
    # Membuat canvas (figure) baru untuk setiap histogram agar tidak tumpang tindih
    plt.figure(figsize=(8, 5))

    # Membuat histogram menggunakan seaborn.
    # kde=True menambahkan garis estimasi kepadatan untuk melihat bentuk distribusi.
    sns.histplot(df_loan[column], kde=True, bins=35)

    # Menambahkan judul yang informatif pada plot
    plt.title(f'Histogram Kolom: {column}', fontsize=15)

    # Menambahkan label untuk sumbu x dan y
    plt.xlabel(column, fontsize=12)
    plt.ylabel('Frekuensi', fontsize=12)

    # Menampilkan plot
    plt.show()

"""# BIVARIATE ANALYSIS

## Kategorikal

### sub grade vs credit risk
"""

plt.figure(figsize=(12, 7))
sns.countplot(x='sub_grade', data=df_loan, order=sorted(df_loan['sub_grade'].unique()), hue='credit_risk', palette={0:'blue', 1:'Red'})
plt.title('sub grade vs credit risk')
plt.xlabel('sub grade')
plt.ylabel('Jumlah')
plt.show()

"""### term vs credit risk"""

plt.figure(figsize=(12, 7))
sns.countplot(x='term', data=df_loan, order=sorted(df_loan['term'].unique()), hue='credit_risk', palette={0:'blue', 1:'Red'})
plt.title('term vs credit risk')
plt.xlabel('term')
plt.ylabel('Jumlah')
plt.show()

"""### emp length vs credit risk"""

plt.figure(figsize=(12, 7))
sns.countplot(x='emp_length', data=df_loan, order=df_loan['emp_length'].unique(), hue='credit_risk', palette={0:'blue', 1:'Red'})
plt.title('emp length vs credit risk')
plt.xlabel('emp length')
plt.ylabel('Jumlah')
plt.show()

"""### home ownership vs credit risk"""

plt.figure(figsize=(12, 7))
sns.countplot(x='home_ownership', data=df_loan, order=sorted(df_loan['home_ownership'].unique()), hue='credit_risk', palette={0:'blue', 1:'Red'})
plt.title('home ownership vs credit risk')
plt.xlabel('home ownership')
plt.ylabel('Jumlah')
plt.show()

"""### purpose vs credit risk"""

plt.figure(figsize=(12, 7))
sns.countplot(y='purpose', data=df_loan, order=sorted(df_loan['purpose'].unique()), hue='credit_risk', palette={0:'blue', 1:'Red'})
plt.title('purpose vs credit risk')
plt.xlabel('purpose')
plt.ylabel('Jumlah')
plt.show()

"""### region vs credit risk"""

plt.figure(figsize=(12, 7))
sns.countplot(x='addr_state', data=df_loan, order=sorted(df_loan['addr_state'].unique()), hue='credit_risk', palette={0:'blue', 1:'Red'})
plt.title('addr state vs credit risk')
plt.xlabel('addrstate')
plt.ylabel('Jumlah')
plt.show()

"""## NUMERIK"""

print(df_loan['credit_risk'].value_counts())

"""### int rate vs Credit Risk"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.boxplot(x='credit_risk', y='int_rate', data=df_loan, palette={'0': 'blue', '1': 'red'})

plt.title('Boxplot Interest Rate vs Credit Risk')
plt.xlabel('Credit Risk (0 = good, 1 = bad)')
plt.ylabel('Interest Rate (%)')
plt.show()

"""### funded amnt vs Credit Risk"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.boxplot(x='credit_risk', y='funded_amnt', data=df_loan, palette={'0': 'blue', '1': 'red'})

plt.title('Boxplot funded amnt vs Credit Risk')
plt.xlabel('Credit Risk (0 = good, 1 = bad)')
plt.ylabel('funded amnt ')
plt.show()

"""### installment vs Credit Risk"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.boxplot(x='credit_risk', y='installment', data=df_loan, palette={'0': 'blue', '1': 'red'})

plt.title('Boxplot installment vs Credit Risk')
plt.xlabel('Credit Risk (0 = good, 1 = bad)')
plt.ylabel('installment')
plt.show()

from matplotlib.ticker import FuncFormatter

plt.figure(figsize=(12, 8))
ax = sns.boxplot(
    x='credit_risk',
    y='annual_inc',
    data=df_loan,
    hue='credit_risk', # Menggunakan hue untuk pewarnaan yang benar
    palette={0: 'cornflowerblue', 1: 'lightcoral'},
    legend=False # Legenda tidak diperlukan karena sumbu-x sudah jelas
)

plt.yscale('log')
plt.title('Distribusi Pendapatan Tahunan Berdasarkan Risiko Kredit', fontsize=16, pad=20)
plt.xlabel('Status Risiko Kredit', fontsize=12)
plt.ylabel('Pendapatan Tahunan (Skala Log)', fontsize=12)
plt.xticks([0, 1], ['Baik (0)', 'Buruk (1)'], fontsize=11)
formatter = FuncFormatter(lambda y, _: f'{int(y):,}')
ax.yaxis.set_major_formatter(formatter)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

"""### dti vs Credit Risk"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.boxplot(x='credit_risk', y='dti', data=df_loan, palette={'0': 'blue', '1': 'red'})

plt.title('Boxplot dti vs Credit Risk')
plt.xlabel('Credit Risk (0 = good, 1 = bad)')
plt.ylabel('dti')
plt.show()

"""### total acc vs Credit Risk"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.boxplot(x='credit_risk', y='total_acc', data=df_loan, palette={'0': 'blue', '1': 'red'})

plt.title('Boxplot total acc vs Credit Risk')
plt.xlabel('Credit Risk (0 = good, 1 = bad)')
plt.ylabel('total acc ')
plt.show()

"""### loan amnt vs Credit Risk"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.boxplot(x='credit_risk', y='loan_amnt', data=df_loan, palette={'0': 'blue', '1': 'red'})

plt.title('Boxplot loan amnt vs Credit Risk')
plt.xlabel('Credit Risk (0 = good, 1 = bad)')
plt.ylabel('loan amnt ')
plt.show()

"""# DATA PREPARATION DAN FEATURE ENGINEERING

## MENGHAPUS KOLOM YANG TIDAK DI PERLUKAN
"""

persentase_null_value = (df_loan.isnull().sum() / len(df_loan)) * 100
persentase = 60.0
cols_to_drop = persentase_null_value[persentase_null_value > persentase].index
df_loan.drop(columns=cols_to_drop, inplace=True)

"""*   Menghapus kolom yang memiliki => 60%


"""

df_loan.shape

kolom_untuk_didelete = ['Unnamed: 0','emp_title','grade','loan_amnt','funded_amnt_inv','id', 'member_id', 'zip_code', 'url',
                        'application_type', 'policy_code','pymnt_plan','out_prncp','out_prncp_inv','total_pymnt',
                        'total_pymnt_inv','total_rec_prncp','total_rec_int','total_rec_late_fee',
                        'recoveries','collection_recovery_fee','last_pymnt_d','last_pymnt_amnt','last_credit_pull_d',
                        'title']
df_loan.drop(columns=kolom_untuk_didelete, inplace=True)

"""*   Kolom 'Unnamed: 0','id', 'member_id', 'zip_code', 'url','pymnt_plan' di hapus karena tidak memiliki informasi berguna untuk prediksi


*   Kolom 'grade', sub_grade, memiliki nilai unik yang sama jadi 'grade' di hapus dan kolom sub_grade dipertahankan untuk mewakili kolom grade.serta untuk menghidari Multicollinearity.

*   Kolom 'loan_amnt','funded_amnt_inv' dan funded_amnt memiliki isi nilai yang sama jadi 'loan_amnt','funded_amnt_inv' dihapus dan kolom funded_amnt dipertahankan untuk mewakili loan_amnt, funded_amnt. serta untuk menghidari Multicollinearity.


*   Kolom 'application_type' hanya memilik 1 nilai unik

*   Kolom 'title' terlalu banyak nilai unik untuk kolom kategorikal

*  Kolom 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv','total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries','collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'last_credit_pull_d' Memiliki data yang ada setelah pinjaman berjalan

## MENGATASI MISSING VALUE
"""

cols_fill_zero = ['mths_since_last_delinq','collections_12_mths_ex_med','delinq_2yrs','inq_last_6mths','pub_rec','acc_now_delinq']

df_loan[cols_fill_zero] = df_loan[cols_fill_zero].fillna(0)

"""

*   Kolom 'collections_12_mths_ex_med' saya mengisi dengan nilai 0 dengan asumsi bahwa nilai kosong itu artinya peminjam tidak ada catatan untuk  collections_12_mths_ex_med

*   kolom 'delinq_2yrs' saya mengisi dengan nilai 0 dengan asumsi bahwa nilai kosong itu artinya peminjam tidak pernah ada insiden kenakalan yang lewat dalam file kredit peminjam selama 2 tahun

*   kolom mths_since_last_delinq saya mengisi dengan nilai 0 dengan asumsi bahwa nilai kosong itu artinya peminjam tidak pernah telat membayar sehingga tidak ada datanya atau kosong

*   dan untuk kolom 'inq_last_6mths','pub_rec','acc_now_delinq' sama dengan di atas





"""

for col in['tot_coll_amt','tot_cur_bal','total_rev_hi_lim','open_acc','total_acc','annual_inc','revol_util']:
    median_value= df_loan[col].median()
    df_loan[col].fillna(median_value, inplace= True)

"""Mengisi dengan nilai median agar tidak terpengaruh oleh outlier"""

df_loan['emp_length'] = df_loan['emp_length'].fillna('Others')

"""Memasukan nilai kosong ke dalam satu kategori baru yaitu Others agar lebih aman dan tidak mengganggu distribusi nilai yang lain"""

df_loan = df_loan[df_loan['delinq_2yrs'] != 29]

"""Menghapus nilai yang janggal pada kolom delinq_2year yang dimana isi nilai ini seharusnya antara 0 sampai 24 yang menunjukan jumlah bulan dalam 2 tahun"""

df_loan.dropna(subset=['earliest_cr_line'], inplace=True)

"""Menghapus baris pada nilai kosong 'earliest_cr_line' karena hanya sedikit nilai kosong pada kolom 'earliest_cr_line'

## CHECK MISSING VALUE SETELAH MEMBERSIHKAN DATA
"""

df_loan.isnull().sum()

"""## MENGUBAH DC DENGAN ND PADA KOLOM addr_state"""

df_loan['addr_state'] = df_loan['addr_state'].replace('DC', 'ND')

"""Karena tidak ada kode DC untuk kota di negara amerika

## FEATURE ENGINEERING KOLOM region
"""

region_mapping = {
    'West': ['CA', 'WA', 'MT', 'HI', 'AK', 'OR', 'ID', 'WY', 'NV', 'CO', 'UT'],
    'Northeast': ['NY', 'NJ', 'PA', 'CT', 'NH', 'RI', 'ME','MA', 'DE','MD','VT'],
    'SouthWest': ['TX', 'AZ', 'NM', 'OK'],
    'SouthEast' :['AR', 'LA', 'MS', 'AL', 'TN', 'KY', 'WV', 'VA', 'NC', 'SC', 'FL', 'GA'],
    'Midwest': ['IL', 'SD', 'ND', 'NE', 'KS', 'MN', 'IA', 'MO', 'WI', 'MI', 'IN', 'OH']
}
def get_region(state):
    for region, states in region_mapping.items():
        if state in states:
            return region

#Membuat kolom baru 'region'
df_loan['region'] = df_loan['addr_state'].apply(get_region)
df_loan.drop('addr_state',axis=1, inplace=True)
print(df_loan['region'].value_counts())

"""Nilai unik pada addr_state terlalu banyak dan dilakukan grouping agar nilai unik berkurang dan di masukan ke dalam kolom baru 'region'

## FEATURE ENGINEERING PADA KOLOM issue_d DAN earliest_cr_line
"""

def convert_to_4_digit_year(date_str):


    month, year_2d_str = date_str.split('-')
    year_2d = int(year_2d_str)
    if year_2d > 14:

        year_4d = 1900 + year_2d
    else:
        year_4d = 2000 + year_2d

    return f"{month}-{year_4d}"


df_loan['issue_d_clean'] = df_loan['issue_d'].apply(convert_to_4_digit_year)
df_loan['earliest_cr_line_clean'] = df_loan['earliest_cr_line'].apply(convert_to_4_digit_year)

df_loan['issue_d'] = pd.to_datetime(df_loan['issue_d_clean'], format='%b-%Y')
df_loan['earliest_cr_line'] = pd.to_datetime(df_loan['earliest_cr_line_clean'], format='%b-%Y')

df_loan.drop(columns=['issue_d_clean', 'earliest_cr_line_clean'], inplace=True)


print(df_loan[['issue_d', 'earliest_cr_line']].head(2))

"""

*   Mengubah tipe data pada kolom issue_d dan earliest_cr_line menjadi datetime kemudian mengubah formatnya menjadi YYYY-MM-DD.
*   Aturan di bawah agar mudah mengubah tahun di bawah 2000 :



1.   Jika tahun pada data lebih dari 14 seperti 89 maka menjadi tahun 1900 + angka tahun pada data
2.   Jika tahun tidak lebih dari 14 seperti 12 maka menjadi tahun 2000 + angka tahun pada data




"""

def process_dates_full(df):
    df_loan['issue_d'] = pd.to_datetime(df_loan['issue_d'], format='%b-%Y')
    df_loan['earliest_cr_line'] = pd.to_datetime(df_loan['earliest_cr_line'], format='%b-%Y')

    # MEMBUAT FITUR BARU: credit_history_length
    df['credit_history_length'] = (df['issue_d'] - df['earliest_cr_line']).dt.days / 30

    # Membuat fitur baru: issue_year
    df['issue_year'] = df['issue_d'].dt.year

    # Membuat fitur baru: issue_month
    df['issue_month'] = df['issue_d'].dt.month


    df.drop(columns=['issue_d', 'earliest_cr_line'], inplace=True)
    return df


df = process_dates_full(df_loan)

df_loan.head(5).T

"""## MENGATASI OUTLIER"""

numerical_cols_IQR = ['mths_since_last_delinq','tot_cur_bal', 'int_rate', 'installment', 'annual_inc', 'open_acc', 'revol_bal', 'revol_util', 'total_acc', 'total_rev_hi_lim']

for col in numerical_cols_IQR:

    print(f"\n--- Statistik '{col}' SEBELUM IQR ---")
    print(df_loan[col].describe())

    Q1 = df_loan[col].quantile(0.25)
    Q3 = df_loan[col].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_loan[col] = np.where(df_loan[col] > upper_bound, upper_bound,
                       np.where(df_loan[col] < lower_bound, lower_bound, df_loan[col]))


    print(f"\n--- Statistik '{col}' SETELAH IQR ---")
    print(df_loan[col].describe())

"""*   Menggunakan IQR untuk mengatasi outlier dengan menentukan batas atas dan bawah, sehingga nilai yang lebih dari batas atas akan di jadikan nilai yang sama dengan batas atas dan begitu juga untuk batas bawah
*   Ada beberapa kolom numerik yang tidak bisa dengan IQR karena data 25% 50% dan 75% nya adalah 0

## SPLIT DATA
"""

X = df_loan.drop('credit_risk', axis=1)
y = df_loan['credit_risk']

print("Data Sebelum di-Split")
print(f"Bentuk Fitur (X): {X.shape}")
print(f"Bentuk Target (y): {y.shape}")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=9,
)

print("Data Setelah di-Split ")
print(f"Bentuk X_train: {X_train.shape}")
print(f"Bentuk X_test: {X_test.shape}")
print(f"Bentuk y_train: {y_train.shape}")
print(f"Bentuk y_test: {y_test.shape}")

print("\nVerifikasi proporsi target di train set:")
print(y_train.value_counts(normalize=True))

print("\nVerifikasi proporsi target di test set:")
print(y_test.value_counts(normalize=True))

""""test_size=0.2" membagi data 80% untuk train dan 20% untuk test

## ENCODING KOLOM KATEGORIKAL

Melakukan Encoding dan Scaling setelah melakukan split data agar data test tidak bocor
"""

ordinal_cols = ['sub_grade','emp_length']
nominal_cols = ['term','home_ownership','verification_status','purpose',
                'initial_list_status','region']

# Ordinal Encoding
grade_order = ['G5','G4','G3','G2','G1', 'F5','F4','F3','F2','F1',
               'E5','E4','E3','E2','E1', 'D5','D4','D3','D2','D1',
               'C5','C4','C3','C2','C1', 'B5','B4','B3','B2','B1',
               'A5','A4','A3','A2','A1']
emp_length_order = [
    'Others','< 1 year', '1 year', '2 years', '3 years', '4 years',
    '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years'
]
or_encoder = OrdinalEncoder(categories=[grade_order,emp_length_order])


X_train[ordinal_cols] = or_encoder.fit_transform(X_train[ordinal_cols])
X_test[ordinal_cols] = or_encoder.transform(X_test[ordinal_cols])



# One-Hot Encoding
ohe = OneHotEncoder(drop='first', sparse_output=False)

train_encoded_cols = ohe.fit_transform(X_train[nominal_cols])
X_train_encoded = pd.DataFrame(train_encoded_cols, columns=ohe.get_feature_names_out(nominal_cols), index=X_train.index)
X_train_final = pd.concat([X_train.drop(columns=nominal_cols), X_train_encoded], axis=1)


test_encoded_cols = ohe.transform(X_test[nominal_cols])
X_test_encoded = pd.DataFrame(test_encoded_cols, columns=ohe.get_feature_names_out(nominal_cols), index=X_test.index)
X_test_final = pd.concat([X_test.drop(columns=nominal_cols), X_test_encoded], axis=1)



print("\nX_train_final:")
X_train_final.head(2)
print("\nX_test_final:")
X_test_final.head(2)

"""



*   Menggunakan OneHotEncoding untuk data Nominal, dan Ordinal Encoding untuk data Ordinal seperti pada kolom sub_grade, emp_length
*   order digunakan untuk menentukan urutan kategori unik pada proses Encoding, Jika tidak proses Encoding akan mulai berdasarkan abjad
*   drop='first' pada OHE akan menghapus kolom pertama setelah di Encoding untuk mengurangi jumlah kolom setelah encoding.



"""

X_train_final.info()

"""## SMOTE"""

#smote = SMOTE(random_state=9)
#X_train_resampled, y_train_resampled = smote.fit_resample(X_train_final, y_train)

#print(pd.Series(y_train).value_counts())

"""## CORRELATION HEATMAP"""

credit_risk_train = pd.concat([X_train_final, y_train], axis=1)
corr = credit_risk_train.corr()

plt.figure(figsize=(20, 20))
heatmap = sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.1, annot_kws={"size": 8})


heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=10)
heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=10)

plt.title('Correlation Heatmap', fontsize=16)
plt.show()

"""## SCALING"""

scaler = StandardScaler()

X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_final), columns=X_train_final.columns, index=X_train_final.index)
X_test_scaled = pd.DataFrame(scaler.transform(X_test_final), columns=X_test_final.columns, index=X_test_final.index)

"""# MODELING"""

print("\n" + "="*20, "PROSES HYPERPARAMETER TUNING", "="*20)

log_reg = LogisticRegression(random_state=9, class_weight='balanced')


param_grid = {
    'C': [100, 10, 1, 0.1, 0.01, 0.001],
    'solver': ['liblinear', 'saga']
}

kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)

grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=kfold, scoring='recall', n_jobs=-1)

grid_search.fit(X_train_scaled, y_train)

best_model = grid_search.best_estimator_
print(f"Parameter terbaik yang ditemukan: {grid_search.best_params_}")

"""class_weight='balanced' memberikan bobot agar class target seimbang antara Good dan Bad

Menggunakan Kfold untuk membagi data train menjadi 5 saat di train pada model

Hyperparamater menggunakan gridsearchCV untuk menemukan parameter terbaik

#EVALUASI
"""

print("\n" + "="*20, "EVALUASI MODEL TERBAIK PADA DATA UJI", "="*20)
y_pred_test = best_model.predict(X_test_scaled)
print("\nHasil Evaluasi pada Data Uji:")
print(classification_report(y_test, y_pred_test))
ConfusionMatrixDisplay.from_estimator(best_model, X_test_scaled, y_test, cmap='Greens')
plt.title("Confusion Matrix - Data Uji")
plt.show()

print("\n" + "="*20, "EVALUASI MODEL TERBAIK PADA DATA LATIH", "="*20)
y_pred_train = best_model.predict(X_train_scaled)
print("\nHasil Evaluasi pada Data Latih:")
print(classification_report(y_train, y_pred_train))
ConfusionMatrixDisplay.from_estimator(best_model, X_train_scaled, y_train, cmap='cividis')
plt.title("Confusion Matrix - Data Latih ")
plt.show()

"""## FEATURE IMPORTANCE"""

print("\n" + "="*20, "ANALISIS FEATURE IMPORTANCE", "="*20)


coefficients = best_model.coef_[0]

feature_importance = pd.DataFrame({
    'Fitur': X_train_scaled.columns,
    'Koefisien': coefficients
})

feature_importance['abs_coefficient'] = feature_importance['Koefisien'].abs()
feature_importance = feature_importance.sort_values(by='abs_coefficient', ascending=False).drop(columns='abs_coefficient')

print("Fitur Paling Berpengaruh Berdasarkan Koefisien Model:")
print(feature_importance)

plt.figure(figsize=(10, 8))
sns.barplot(x='Koefisien', y='Fitur', data=feature_importance, palette='viridis')
plt.title('Feature Importance Berdasarkan Koefisien Regresi Logistik', fontsize=16)
plt.xlabel('Nilai Koefisien', fontsize=12)
plt.ylabel('Fitur', fontsize=12)
plt.show()

"""#MODELING RANDOM FOREST"""

print("\n" + "="*20, "TUNING MODEL RANDOM FOREST", "="*20)

rf = RandomForestClassifier(random_state=9, class_weight='balanced')
param_grid_rf = {
    'n_estimators': [300, 400 ],
    'max_depth': [10, 20, None],
    'min_samples_split': [2,5]
}

grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf,cv=3, scoring='recall', n_jobs=2)
grid_search_rf.fit(X_train_scaled, y_train)
best_model_rf = grid_search_rf.best_estimator_
print(f"Parameter terbaik untuk Random Forest: {grid_search_rf.best_params_}")

"""#EVALUASI RF"""

# ---  Evaluasi Model Terbaik (Random Forest) ---
print("\n" + "="*20, "EVALUASI MODEL RANDOM FOREST", "="*20)

# Evaluasi pada Data Uji
y_pred_rf_test = best_model_rf.predict(X_test_scaled)
print("\nHasil Evaluasi pada Data Uji:")
print(classification_report(y_test, y_pred_rf_test))
ConfusionMatrixDisplay.from_estimator(best_model_rf, X_test_scaled, y_test, cmap='Reds')
plt.title("Confusion Matrix (Test Set) - Random Forest")
plt.show()

# Evaluasi pada Data Latih
y_pred_rf_train = best_model_rf.predict(X_train_scaled)
print("\nHasil Evaluasi pada Data Latih:")
print(classification_report(y_train, y_pred_rf_train))

"""##FEATURE IMPORTANCE RF"""

# ---  Analisis Feature Importance (Random Forest) ---
print("\n" + "="*20, "ANALISIS FEATURE IMPORTANCE (RANDOM FOREST)", "="*20)

importances = best_model_rf.feature_importances_
feature_names = X_train_scaled.columns

feature_importance_rf = pd.DataFrame({'Fitur': feature_names, 'Importance': importances})
feature_importance_rf = feature_importance_rf.sort_values(by='Importance', ascending=False)

print("Fitur Paling Berpengaruh Berdasarkan Random Forest:")
print(feature_importance_rf)

plt.figure(figsize=(10, 8))
sns.barplot(x='Importance', y='Fitur', data=feature_importance_rf, palette='viridis')
plt.title('Feature Importance dari Model Random Forest', fontsize=16)
plt.xlabel('Tingkat Kepentingan (Importance)', fontsize=12)
plt.ylabel('Fitur', fontsize=12)
plt.show()